{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset element_spec={'file_name': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}>,\n",
       " 'test': <PrefetchDataset element_spec={'file_name': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='oxford_iiit_pet',\n",
       "    full_name='oxford_iiit_pet/3.2.0',\n",
       "    description=\"\"\"\n",
       "    The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200\n",
       "    images for each class. The images have large variations in scale, pose and\n",
       "    lighting. All images have an associated ground truth annotation of breed.\n",
       "    \"\"\",\n",
       "    homepage='http://www.robots.ox.ac.uk/~vgg/data/pets/',\n",
       "    data_path='/Users/rayaq/tensorflow_datasets/oxford_iiit_pet/3.2.0',\n",
       "    download_size=773.52 MiB,\n",
       "    dataset_size=774.69 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'file_name': Text(shape=(), dtype=tf.string),\n",
       "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=37),\n",
       "        'segmentation_mask': Image(shape=(None, None, 1), dtype=tf.uint8),\n",
       "        'species': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=3669, num_shards=4>,\n",
       "        'train': <SplitInfo num_examples=3680, num_shards=4>,\n",
       "    },\n",
       "    citation=\"\"\"@InProceedings{parkhi12a,\n",
       "      author       = \"Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V.\",\n",
       "      title        = \"Cats and Dogs\",\n",
       "      booktitle    = \"IEEE Conference on Computer Vision and Pattern Recognition\",\n",
       "      year         = \"2012\",\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for loading values\n",
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_mask -= 1\n",
    "    return input_image, input_mask\n",
    "\n",
    "def load_image(datapoint):\n",
    "    input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import variables\n",
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset element_spec=(TensorSpec(shape=(128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augment(tf.keras.layers.Layer):\n",
    "    def __init__(self, seed=42):\n",
    "        super().__init__()\n",
    "        # both use the same seed, so they'll make the same random changes.\n",
    "        self.augment_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
    "        self.augment_labels = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
    "\n",
    "    def call(self, inputs, labels):\n",
    "        inputs = self.augment_inputs(inputs)\n",
    "        labels = self.augment_labels(labels)\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = (\n",
    "    train_images\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    "    .map(Augment())\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_batches = test_images.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation augment/random_flip/stateful_uniform_full_int/RngReadAndSkip: Could not satisfy explicit device specification '' because the node {{colocation_node augment/random_flip/stateful_uniform_full_int/RngReadAndSkip}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nRngReadAndSkip: CPU \n_Arg: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  augment_random_flip_stateful_uniform_full_int_rngreadandskip_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  augment/random_flip/stateful_uniform_full_int/RngReadAndSkip (RngReadAndSkip) \n\n\t [[{{node augment/random_flip/stateful_uniform_full_int/RngReadAndSkip}}]] [Op:MakeIterator]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m images, masks \u001b[39min\u001b[39;00m train_batches\u001b[39m.\u001b[39mtake(\u001b[39m2\u001b[39m):\n\u001b[1;32m      2\u001b[0m     sample_image, sample_mask \u001b[39m=\u001b[39m images, masks\n\u001b[1;32m      3\u001b[0m     plt\u001b[39m.\u001b[39mimshow(sample_image)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:486\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=483'>484</a>\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=484'>485</a>\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=485'>486</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=486'>487</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=487'>488</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=488'>489</a>\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:755\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=750'>751</a>\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=751'>752</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=752'>753</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=753'>754</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=754'>755</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=756'>757</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:787\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=781'>782</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=782'>783</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deleter \u001b[39m=\u001b[39m (\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=783'>784</a>\u001b[0m       gen_dataset_ops\u001b[39m.\u001b[39manonymous_iterator_v2(\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=784'>785</a>\u001b[0m           output_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types,\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=785'>786</a>\u001b[0m           output_shapes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_shapes))\n\u001b[0;32m--> <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=786'>787</a>\u001b[0m   gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=787'>788</a>\u001b[0m   \u001b[39m# Delete the resource when this object is deleted\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=788'>789</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resource_deleter \u001b[39m=\u001b[39m IteratorResourceDeleter(\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=789'>790</a>\u001b[0m       handle\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource,\n\u001b[1;32m    <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py?line=790'>791</a>\u001b[0m       deleter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deleter)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3319\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py?line=3316'>3317</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py?line=3317'>3318</a>\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py?line=3318'>3319</a>\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py?line=3319'>3320</a>\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py?line=3320'>3321</a>\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7186\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/framework/ops.py?line=7183'>7184</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/framework/ops.py?line=7184'>7185</a>\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///Users/rayaq/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/framework/ops.py?line=7185'>7186</a>\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation augment/random_flip/stateful_uniform_full_int/RngReadAndSkip: Could not satisfy explicit device specification '' because the node {{colocation_node augment/random_flip/stateful_uniform_full_int/RngReadAndSkip}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nRngReadAndSkip: CPU \n_Arg: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  augment_random_flip_stateful_uniform_full_int_rngreadandskip_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  augment/random_flip/stateful_uniform_full_int/RngReadAndSkip (RngReadAndSkip) \n\n\t [[{{node augment/random_flip/stateful_uniform_full_int/RngReadAndSkip}}]] [Op:MakeIterator]"
     ]
    }
   ],
   "source": [
    "for images, masks in train_batches.take(2):\n",
    "    sample_image, sample_mask = images[0], masks[0]\n",
    "    plt.imshow(sample_image)\n",
    "    # display([sample_image, sample_mask])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9af30963835933b21408ee5eecfbf720fcadebfe3f3c64ab8e2d3dc6f0d4daa2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
